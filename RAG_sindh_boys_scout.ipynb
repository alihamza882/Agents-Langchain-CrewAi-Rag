{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alihamza882/Agents-Langchain-CrewAi-Rag/blob/main/RAG_sindh_boys_scout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evjGLA8Jx5k8"
      },
      "outputs": [],
      "source": [
        "# Pakistan zinda bad, we love our country.\n",
        "# 0         1     2    3  4.   5.   6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "jgK8e2vq6gvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "U5a_LR0V7QEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3Q5zbNgD72OA",
        "outputId": "ca68e58a-81e3-46c6-fa7b-f6ed96d7a495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"What is the meaning of life?\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "# print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "result['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wslvg_cS6hQG",
        "outputId": "144311ad-3425-4b27-c673-025b71e22a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.02854543,\n",
              " 0.044588115,\n",
              " -0.034197364,\n",
              " -0.0042663575,\n",
              " -0.04079577,\n",
              " 0.012999958,\n",
              " 0.018053582,\n",
              " 0.06015144,\n",
              " -0.0028713925,\n",
              " 0.009951648,\n",
              " 0.024832657,\n",
              " -0.01683923,\n",
              " 0.09940116,\n",
              " -0.031990346,\n",
              " 0.018328529,\n",
              " -0.109134205,\n",
              " 0.001190296,\n",
              " 0.0014311911,\n",
              " -0.083155245,\n",
              " -0.010203233,\n",
              " 0.019211812,\n",
              " 0.0010217889,\n",
              " 0.053874534,\n",
              " -0.0150861535,\n",
              " -0.003189089,\n",
              " 0.019626662,\n",
              " -0.0074312133,\n",
              " -0.036586244,\n",
              " -0.008509182,\n",
              " -0.017352631,\n",
              " 0.058202818,\n",
              " 0.05446324,\n",
              " 0.01571296,\n",
              " -0.021822602,\n",
              " 0.048009068,\n",
              " 0.022641798,\n",
              " -0.0069730366,\n",
              " 0.054272633,\n",
              " 0.025922865,\n",
              " -0.027334303,\n",
              " -0.07256842,\n",
              " 0.028509492,\n",
              " -0.03564165,\n",
              " 0.060492564,\n",
              " -0.022731686,\n",
              " -0.030770157,\n",
              " -0.006176277,\n",
              " -0.021891864,\n",
              " -0.019659325,\n",
              " 0.0643669,\n",
              " 0.03154234,\n",
              " 0.017379418,\n",
              " -0.03679774,\n",
              " 0.016511764,\n",
              " -0.02536976,\n",
              " -0.022270117,\n",
              " -0.012396498,\n",
              " -0.032805424,\n",
              " 0.054154944,\n",
              " -0.04823156,\n",
              " -0.021759441,\n",
              " -0.03370158,\n",
              " -0.025460402,\n",
              " -0.017531719,\n",
              " -0.052902102,\n",
              " 0.04005264,\n",
              " -0.022417234,\n",
              " 0.023286799,\n",
              " -0.081740536,\n",
              " 0.057951722,\n",
              " -0.009130241,\n",
              " 0.040680293,\n",
              " -0.026519705,\n",
              " 0.03940553,\n",
              " -0.009711097,\n",
              " 0.034678303,\n",
              " 0.022007594,\n",
              " 0.013833644,\n",
              " -0.037151057,\n",
              " 0.03425778,\n",
              " -0.037425302,\n",
              " 0.0133839715,\n",
              " 0.062417556,\n",
              " 0.05847619,\n",
              " 0.010972301,\n",
              " 0.0069226264,\n",
              " -0.028345693,\n",
              " -0.025934424,\n",
              " -0.08300387,\n",
              " -0.018701842,\n",
              " 0.051876634,\n",
              " 0.028144632,\n",
              " 0.0050556627,\n",
              " 0.032798667,\n",
              " 0.065246835,\n",
              " -0.030897865,\n",
              " -0.05739043,\n",
              " -0.075857975,\n",
              " 0.013478357,\n",
              " 0.06728078,\n",
              " 0.058566026,\n",
              " 0.004352499,\n",
              " 0.004930005,\n",
              " -0.04687863,\n",
              " 0.047707375,\n",
              " 0.09346361,\n",
              " -0.033218864,\n",
              " -0.031682696,\n",
              " -0.035492342,\n",
              " -0.01704582,\n",
              " 0.0070146834,\n",
              " -0.070768684,\n",
              " 0.033927422,\n",
              " -0.05199852,\n",
              " 0.023873666,\n",
              " -0.07814866,\n",
              " -0.0045958003,\n",
              " 0.008596137,\n",
              " -0.014557764,\n",
              " -0.005185891,\n",
              " 0.019220637,\n",
              " 0.06736503,\n",
              " -0.0036469845,\n",
              " 0.029749395,\n",
              " 0.06519027,\n",
              " -0.0017471175,\n",
              " 0.0032194257,\n",
              " -0.058492143,\n",
              " -0.04441574,\n",
              " -0.02082184,\n",
              " 0.09642446,\n",
              " -0.1019518,\n",
              " -0.014023612,\n",
              " 0.0124329,\n",
              " -0.03430263,\n",
              " 0.017259782,\n",
              " 0.09509829,\n",
              " -0.0046976367,\n",
              " 0.014962477,\n",
              " -0.014655782,\n",
              " 0.013355405,\n",
              " -0.025665203,\n",
              " -0.044942174,\n",
              " 0.025182499,\n",
              " 0.017465375,\n",
              " -0.03649158,\n",
              " 0.041676275,\n",
              " 0.0115632955,\n",
              " -0.059281666,\n",
              " -0.0076066344,\n",
              " -0.020777298,\n",
              " -0.02422031,\n",
              " 0.062161032,\n",
              " 0.004218794,\n",
              " -0.008247845,\n",
              " 0.0025803575,\n",
              " 0.063738205,\n",
              " -0.0257109,\n",
              " 0.095686235,\n",
              " -0.027317889,\n",
              " -0.0018857537,\n",
              " -0.078989305,\n",
              " -0.03540763,\n",
              " 0.0067127054,\n",
              " -0.048317876,\n",
              " -0.030285196,\n",
              " 0.023211101,\n",
              " -0.0491988,\n",
              " 0.010719925,\n",
              " 0.02444096,\n",
              " -0.0052104676,\n",
              " 0.008697184,\n",
              " -0.07112967,\n",
              " -0.033053268,\n",
              " -0.024818258,\n",
              " 0.0080466885,\n",
              " -0.022770239,\n",
              " -0.0047805742,\n",
              " -0.010209843,\n",
              " 0.03673981,\n",
              " 0.09795194,\n",
              " 0.03386203,\n",
              " -0.010665188,\n",
              " -0.07381909,\n",
              " 0.00068866805,\n",
              " -0.025717223,\n",
              " -0.0027137904,\n",
              " 0.04281671,\n",
              " 0.034393556,\n",
              " 0.059981614,\n",
              " -0.056784473,\n",
              " 0.030799013,\n",
              " 0.0035953694,\n",
              " 0.034763683,\n",
              " 0.014165773,\n",
              " -0.04174826,\n",
              " 0.061088957,\n",
              " -0.012045537,\n",
              " -0.051974565,\n",
              " -0.0055955644,\n",
              " 0.007566413,\n",
              " -0.03619617,\n",
              " -0.0193453,\n",
              " -0.038998786,\n",
              " 0.016063262,\n",
              " -0.0075189867,\n",
              " -0.045611285,\n",
              " -0.04747799,\n",
              " 0.047357876,\n",
              " 0.0055609345,\n",
              " -0.029912258,\n",
              " -0.01027596,\n",
              " -0.009503956,\n",
              " -0.022230182,\n",
              " 0.047264725,\n",
              " 0.033944495,\n",
              " 0.0636137,\n",
              " -0.0061410535,\n",
              " 0.10799254,\n",
              " 0.023873555,\n",
              " -0.024063213,\n",
              " -0.01934859,\n",
              " -0.019175187,\n",
              " -0.02375712,\n",
              " 0.010766843,\n",
              " 0.010511031,\n",
              " -0.020831015,\n",
              " -0.0415524,\n",
              " -0.021580799,\n",
              " -0.03839475,\n",
              " 0.015841262,\n",
              " 0.0064048977,\n",
              " 0.00884391,\n",
              " -0.012423147,\n",
              " -0.0060453643,\n",
              " 0.02140582,\n",
              " -0.008806144,\n",
              " 0.037548866,\n",
              " -0.031451035,\n",
              " -0.023714807,\n",
              " 0.009285378,\n",
              " -0.00047728888,\n",
              " -0.018435625,\n",
              " 0.010426646,\n",
              " 0.07636751,\n",
              " 0.07757101,\n",
              " 0.03991539,\n",
              " 0.06917671,\n",
              " 0.0016628958,\n",
              " -0.091617554,\n",
              " -0.026956096,\n",
              " -0.013664855,\n",
              " -0.054339245,\n",
              " -0.08310413,\n",
              " -0.025953747,\n",
              " -0.033568814,\n",
              " 0.034448486,\n",
              " 0.0032975704,\n",
              " 0.015053127,\n",
              " -0.005894113,\n",
              " 0.029622843,\n",
              " -0.08048511,\n",
              " -0.013663298,\n",
              " -0.029040001,\n",
              " -0.043319844,\n",
              " -0.058795128,\n",
              " -0.030551378,\n",
              " -0.03321159,\n",
              " 0.03361637,\n",
              " -0.0583398,\n",
              " 0.048462477,\n",
              " -0.019440303,\n",
              " -0.002224581,\n",
              " -0.013960494,\n",
              " 0.043021582,\n",
              " 0.028916152,\n",
              " 0.013766024,\n",
              " 0.029295404,\n",
              " 0.028375948,\n",
              " -0.012632167,\n",
              " 0.009296993,\n",
              " -0.029445387,\n",
              " -0.00021846336,\n",
              " -0.0015232554,\n",
              " 0.013555971,\n",
              " -0.06027861,\n",
              " 0.0022099994,\n",
              " 0.0020799884,\n",
              " -0.012007119,\n",
              " 0.008591618,\n",
              " 0.048698094,\n",
              " 0.047572628,\n",
              " 0.017961571,\n",
              " -0.04480692,\n",
              " 0.01596784,\n",
              " 0.026624791,\n",
              " 0.04592755,\n",
              " 0.023339162,\n",
              " 0.012650808,\n",
              " 0.014623401,\n",
              " 0.059190698,\n",
              " 0.053951625,\n",
              " -0.012018796,\n",
              " 0.025127882,\n",
              " 0.013777736,\n",
              " 0.008772696,\n",
              " 0.06242213,\n",
              " -0.02985679,\n",
              " 0.015534353,\n",
              " 0.008786879,\n",
              " 0.0021978319,\n",
              " 0.011586468,\n",
              " -0.02561069,\n",
              " 0.031158268,\n",
              " -0.07818875,\n",
              " -0.025129631,\n",
              " -0.15375015,\n",
              " -0.028578915,\n",
              " -0.019318363,\n",
              " -0.020512082,\n",
              " -0.006895941,\n",
              " 0.025423868,\n",
              " 0.016258566,\n",
              " -0.013225587,\n",
              " 0.07140959,\n",
              " -0.03596512,\n",
              " -0.027768183,\n",
              " 0.018441642,\n",
              " 0.0016754153,\n",
              " -0.009046769,\n",
              " 0.0068947347,\n",
              " 0.010378478,\n",
              " -0.004311906,\n",
              " -0.036049224,\n",
              " 0.0429449,\n",
              " -0.00087607105,\n",
              " -0.021248715,\n",
              " 0.039782412,\n",
              " 0.03250818,\n",
              " 0.050120413,\n",
              " -0.011048507,\n",
              " 0.0046043964,\n",
              " 0.012511691,\n",
              " 0.024216538,\n",
              " 0.01150548,\n",
              " -0.02745774,\n",
              " -0.0051559354,\n",
              " -0.007308025,\n",
              " 0.019659724,\n",
              " -0.022055222,\n",
              " 0.00027937818,\n",
              " 0.044644978,\n",
              " 0.013013166,\n",
              " 0.005594769,\n",
              " -0.009612895,\n",
              " -0.025433125,\n",
              " 0.07727911,\n",
              " 0.031199932,\n",
              " 0.038574066,\n",
              " 0.007593594,\n",
              " -0.018812446,\n",
              " -0.012732279,\n",
              " -0.0003708816,\n",
              " -0.017922256,\n",
              " -0.012979617,\n",
              " -0.048761148,\n",
              " 0.013668185,\n",
              " 0.039892722,\n",
              " 0.01600722,\n",
              " -0.015836455,\n",
              " 0.05010714,\n",
              " -0.023271231,\n",
              " -0.0015552061,\n",
              " 0.008744261,\n",
              " -0.0021387269,\n",
              " -0.0138165355,\n",
              " -0.011505079,\n",
              " 0.0383287,\n",
              " 0.032180313,\n",
              " -0.06972529,\n",
              " -0.04253552,\n",
              " -0.035327293,\n",
              " -0.03087898,\n",
              " -0.008225923,\n",
              " -0.057406187,\n",
              " 0.06683099,\n",
              " -0.021594517,\n",
              " -0.005994046,\n",
              " 0.022828693,\n",
              " 0.022839233,\n",
              " -0.03893198,\n",
              " 0.05164902,\n",
              " 0.057929542,\n",
              " 0.021702295,\n",
              " 0.006756328,\n",
              " 0.0020226631,\n",
              " -0.04540625,\n",
              " 0.0411206,\n",
              " -0.0064312797,\n",
              " 0.046170663,\n",
              " -0.02217186,\n",
              " -0.04092706,\n",
              " 0.09603613,\n",
              " 0.010617954,\n",
              " -0.019166118,\n",
              " 0.004992475,\n",
              " 0.08547908,\n",
              " 0.0042816126,\n",
              " -0.011178713,\n",
              " -0.036315963,\n",
              " -0.0397458,\n",
              " 0.0035810445,\n",
              " -0.0073561026,\n",
              " -0.0011699863,\n",
              " -0.058471896,\n",
              " -0.01679719,\n",
              " -0.022455424,\n",
              " 0.004091696,\n",
              " -0.001995662,\n",
              " 0.03065391,\n",
              " 0.00027773026,\n",
              " -0.013209596,\n",
              " 0.0062156287,\n",
              " -0.0019772635,\n",
              " 0.026441118,\n",
              " -0.08084242,\n",
              " 0.00813773,\n",
              " 0.011137467,\n",
              " 0.025003403,\n",
              " 0.039739534,\n",
              " 0.04352838,\n",
              " -0.010362335,\n",
              " -0.005326726,\n",
              " 0.026611479,\n",
              " 0.03678279,\n",
              " 0.020289298,\n",
              " -0.00024059122,\n",
              " 0.028297735,\n",
              " -0.058491826,\n",
              " -0.019358084,\n",
              " -0.009499252,\n",
              " -0.013873281,\n",
              " 0.0032195828,\n",
              " 0.04456959,\n",
              " -0.0029241447,\n",
              " 0.008418838,\n",
              " 0.03416341,\n",
              " 0.012652945,\n",
              " -0.030445265,\n",
              " 0.015912598,\n",
              " -0.015061086,\n",
              " -0.004397588,\n",
              " -0.076873265,\n",
              " -0.022693606,\n",
              " -0.017148094,\n",
              " 0.008034367,\n",
              " -0.021009823,\n",
              " -0.013641983,\n",
              " -0.030586809,\n",
              " 0.063050985,\n",
              " -0.0058573247,\n",
              " -0.03037537,\n",
              " 0.06859101,\n",
              " 0.007416954,\n",
              " 0.013147328,\n",
              " -0.03752198,\n",
              " -0.030428246,\n",
              " 0.053029884,\n",
              " -0.022908261,\n",
              " 0.05607778,\n",
              " 0.05492161,\n",
              " 0.013270513,\n",
              " 0.0070847725,\n",
              " 0.029913813,\n",
              " -0.010489726,\n",
              " 0.007844949,\n",
              " 0.07760543,\n",
              " -0.03246045,\n",
              " -0.013374177,\n",
              " -0.027256502,\n",
              " -0.004605633,\n",
              " 0.030556176,\n",
              " -0.025936672,\n",
              " 0.04827568,\n",
              " 0.044143107,\n",
              " -0.01873767,\n",
              " -0.031347197,\n",
              " -0.026854562,\n",
              " 0.031382143,\n",
              " 0.013992115,\n",
              " 0.021271078,\n",
              " 0.027894089,\n",
              " -0.024505738,\n",
              " -0.07478747,\n",
              " 0.013540895,\n",
              " -0.017613562,\n",
              " 0.01590729,\n",
              " 0.017141188,\n",
              " 0.04708115,\n",
              " 0.019568153,\n",
              " 0.091656715,\n",
              " -0.004865123,\n",
              " -0.019308813,\n",
              " -0.0053966944,\n",
              " -0.0278622,\n",
              " 0.012864926,\n",
              " -0.061174583,\n",
              " -0.041453917,\n",
              " 0.075621046,\n",
              " -0.0070187845,\n",
              " 0.01906601,\n",
              " 0.0054263994,\n",
              " 0.012566397,\n",
              " -0.019087587,\n",
              " -0.043440256,\n",
              " 0.041887432,\n",
              " -0.014445988,\n",
              " 0.04691199,\n",
              " -0.0016946428,\n",
              " 0.071609624,\n",
              " -0.024095738,\n",
              " -0.029031072,\n",
              " 0.0023203683,\n",
              " 0.014458297,\n",
              " 0.010492939,\n",
              " -0.005559697,\n",
              " 0.025936546,\n",
              " 0.009190466,\n",
              " -0.0027095198,\n",
              " -0.013050847,\n",
              " -0.020220019,\n",
              " 0.056056578,\n",
              " 0.03650916,\n",
              " 0.019963812,\n",
              " -0.013089996,\n",
              " 0.05316529,\n",
              " 0.02269551,\n",
              " 0.0141424555,\n",
              " 0.022176167,\n",
              " 0.020095332,\n",
              " 0.011605739,\n",
              " 0.0020735825,\n",
              " 0.003068887,\n",
              " 0.009191726,\n",
              " 0.025579473,\n",
              " -0.008541693,\n",
              " -0.03808776,\n",
              " 0.04622485,\n",
              " -0.029493613,\n",
              " 0.07711512,\n",
              " 0.014877751,\n",
              " -0.029058069,\n",
              " 0.025354061,\n",
              " 0.03530013,\n",
              " 0.0014759303,\n",
              " -0.021830602,\n",
              " 0.02163411,\n",
              " 0.025770994,\n",
              " -0.06815127,\n",
              " 0.021125901,\n",
              " 0.0019301678,\n",
              " 0.002210321,\n",
              " -0.00305364,\n",
              " -0.021801703,\n",
              " -0.051318586,\n",
              " -0.033611473,\n",
              " 0.012315321,\n",
              " 0.0072091133,\n",
              " 0.0014005301,\n",
              " -0.023998646,\n",
              " 0.0026291292,\n",
              " -0.015098267,\n",
              " -0.011970929,\n",
              " -0.030961366,\n",
              " 0.021716155,\n",
              " 0.019829318,\n",
              " -0.0408635,\n",
              " -0.0088035865,\n",
              " 0.02354545,\n",
              " -0.035932545,\n",
              " 0.061214827,\n",
              " 0.005042119,\n",
              " 0.053205136,\n",
              " 0.012700384,\n",
              " -0.0013505232,\n",
              " -0.02219724,\n",
              " 0.017605027,\n",
              " 0.0109856445,\n",
              " -0.0046386044,\n",
              " -0.007891236,\n",
              " -0.025283262,\n",
              " 0.05328586,\n",
              " 0.009774557,\n",
              " -0.036375165,\n",
              " -0.026973603,\n",
              " -0.024808131,\n",
              " -0.0313296,\n",
              " -0.012596162,\n",
              " 0.02893709,\n",
              " 0.007063438,\n",
              " 0.012943186,\n",
              " -0.014554011,\n",
              " 0.022427145,\n",
              " 0.009753417,\n",
              " -0.030994788,\n",
              " -0.095215425,\n",
              " -0.015310255,\n",
              " -0.03325391,\n",
              " 0.0049246587,\n",
              " -0.009970491,\n",
              " 0.0069147805,\n",
              " 0.049630444,\n",
              " -0.051078644,\n",
              " 0.0710505,\n",
              " -0.07212227,\n",
              " 0.014028713,\n",
              " -0.0039652484,\n",
              " -0.030573502,\n",
              " 0.035072844,\n",
              " -0.025866162,\n",
              " -0.033041764,\n",
              " 0.023931714,\n",
              " 0.014035653,\n",
              " -0.015747368,\n",
              " -0.042261735,\n",
              " 0.0028005617,\n",
              " -0.0047397106,\n",
              " -0.0016750308,\n",
              " -0.007684546,\n",
              " 0.022748126,\n",
              " -0.05401668,\n",
              " 0.022321891,\n",
              " 0.05747806,\n",
              " -0.032267727,\n",
              " -0.0018111368,\n",
              " 0.021240143,\n",
              " 0.015935048,\n",
              " -0.017525177,\n",
              " 0.035998467,\n",
              " 0.009683403,\n",
              " -0.0242088,\n",
              " 0.015660904,\n",
              " 0.048446238,\n",
              " 0.019246493,\n",
              " -0.048423514,\n",
              " 0.06908145,\n",
              " -0.049179938,\n",
              " -0.013505337,\n",
              " 0.061395,\n",
              " 0.028108947,\n",
              " -0.033591855,\n",
              " -0.038586985,\n",
              " 0.041065104,\n",
              " -0.022049988,\n",
              " -0.010130617,\n",
              " 0.038356528,\n",
              " -0.034783028,\n",
              " -0.043130342,\n",
              " -0.0005808886,\n",
              " -0.04879479,\n",
              " 0.0053223893,\n",
              " -0.0228413,\n",
              " 0.045616776,\n",
              " -0.007167411,\n",
              " -0.03421718,\n",
              " 0.0073885787,\n",
              " 0.040428832,\n",
              " 0.025090184,\n",
              " -0.024634155,\n",
              " -0.024775982,\n",
              " 0.0052057267,\n",
              " 0.05093614,\n",
              " 0.042788316,\n",
              " 0.024823798,\n",
              " -0.029019883,\n",
              " 0.03016593,\n",
              " 0.021206478,\n",
              " -0.012097347,\n",
              " 0.002654971,\n",
              " 0.029118014,\n",
              " 0.018068524,\n",
              " -0.017020179,\n",
              " -0.022816472,\n",
              " -0.063054584,\n",
              " -0.00427345,\n",
              " 0.026169498,\n",
              " 0.08122146,\n",
              " -0.048106845,\n",
              " -0.021307718,\n",
              " 0.000573938,\n",
              " -0.041324914,\n",
              " -0.033583045,\n",
              " 0.018485945,\n",
              " -0.009407308,\n",
              " 0.01742343,\n",
              " 0.0328296,\n",
              " -0.050955404,\n",
              " 0.051715422,\n",
              " -0.06056332,\n",
              " -0.058261856,\n",
              " -0.009281477,\n",
              " -0.011629536,\n",
              " -0.052582953,\n",
              " 0.0048258896,\n",
              " 0.04804673,\n",
              " -0.007417617,\n",
              " -0.006769257,\n",
              " -0.013769851,\n",
              " -0.07769279,\n",
              " 0.022878287,\n",
              " -0.009451909,\n",
              " 0.046827216,\n",
              " 0.043176863,\n",
              " 0.014981078,\n",
              " -0.012839531,\n",
              " 0.02928201,\n",
              " -0.0042603286,\n",
              " 0.014360433,\n",
              " 0.028610492,\n",
              " 0.018387672,\n",
              " -0.0038107908,\n",
              " -0.03366308,\n",
              " 0.0053267474,\n",
              " 0.0572671,\n",
              " 0.0006855626,\n",
              " -0.027601944,\n",
              " -0.07033053,\n",
              " 0.028943876,\n",
              " -0.033198193,\n",
              " 0.053086396,\n",
              " 0.07436674,\n",
              " 0.020729132,\n",
              " -0.031300083,\n",
              " 0.049042925,\n",
              " -0.01617157,\n",
              " -0.02372223,\n",
              " -0.017318686,\n",
              " 0.02420875,\n",
              " 0.00021474871,\n",
              " -0.008650192,\n",
              " 0.06548937,\n",
              " -0.034736387,\n",
              " -0.058506683,\n",
              " -0.049474478,\n",
              " -0.012243532,\n",
              " -0.013708403,\n",
              " -0.055309515,\n",
              " -0.013009869,\n",
              " -0.04248218,\n",
              " -0.02547653,\n",
              " -0.084748425,\n",
              " 0.004215639,\n",
              " 0.038781103,\n",
              " 0.06744112,\n",
              " 0.04144784,\n",
              " -0.002465784,\n",
              " -0.017555721,\n",
              " -0.005858821,\n",
              " 0.047553077,\n",
              " 0.047972098,\n",
              " -0.021811942,\n",
              " 0.019362554,\n",
              " -0.021370107,\n",
              " -0.0034753596,\n",
              " -0.08682825,\n",
              " 1.2328685e-05,\n",
              " 0.0107819205,\n",
              " -0.033175968]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LRebzTJABUh",
        "outputId": "730849d2-9012-444c-f392-8be3beaedfc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whzpN01Z9hPA",
        "outputId": "d291323f-4094-4f29-ca0f-741341d267f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1ZqSNYKA84oQ",
        "outputId": "948d4a43-1164-40e6-c268-bbbb6d4f9eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Vector Stores & Retreival using Chroma DB"
      ],
      "metadata": {
        "id": "eyrCQBs8AANE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPpBBX9g-PKl",
        "outputId": "96667ad4-f3ea-4dd6-dc0e-ddb142c519d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "w4Wd_L8zAJTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "uxHZV_umADw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain_openai"
      ],
      "metadata": {
        "id": "wrgG9s0RBRo9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e167f5f1-6818-4df0-dc78-cf963b055434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m409.6/411.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "uLq9TZU5BpZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "H6v2VV9lBNlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4F_AqazDjvc",
        "outputId": "c1c6786e-9c63-445a-c9bc-5e252c9b34d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV6SYPkLCUZf",
        "outputId": "2f7280d6-1c3e-426c-caa0-3cff763cd6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7af12613acb0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enYsspQlCVTx",
        "outputId": "49ffcaef-bcfa-4254-efc7-f6244d969ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhUxC04ODcB_",
        "outputId": "7fe25a07-76fa-431a-f96b-4516379a6fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqdDbqlqD66I",
        "outputId": "7fd90679-f5ca-4444-8bd4-a1aa048ba47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              "  0.37521976232528687),\n",
              " (Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              "  0.48278287053108215),\n",
              " (Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  0.49597978591918945),\n",
              " (Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
              "  0.4974355101585388)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings().embed_query(\"cat\")\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5wF724BDNb5",
        "outputId": "ff771a3f-b5f5-4c50-88e4-c7de123c42a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              " Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding"
      ],
      "metadata": {
        "id": "fVH5rbdBFGiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrievers"
      ],
      "metadata": {
        "id": "ZJBBUPFvFkym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"shark\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndnSdfyoEsfz",
        "outputId": "fcf437ca-57d9-4847-eec8-d6958f51f8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJLP_WTbGxXP",
        "outputId": "77baddc2-2ea5-4ae4-99b9-96848edcb5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "B5Qg_8mtGExp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vEIe1ORnGv5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "rKGDcuBQI63Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ],
      "metadata": {
        "id": "Sc2yWh5BJJuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bs3oaRLCJHDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PiJt_KJSJHBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke(\"tell me about Allama Iqbal\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCGSNa3Jn5j",
        "outputId": "2b158a31-0119-41ed-dbdb-f28f0b217e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided text does not contain any information about Allama Iqbal.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now use google gemini embedding model for retriver\n",
        "https://python.langchain.com/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html#langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "kv5FmiyvL0x_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face detection with embedding"
      ],
      "metadata": {
        "id": "Os-OJ_8ySpgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeQQ9ohuUMqS",
        "outputId": "003af214-63a3-4f84-9b86-ab64033363f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeWUwMq_ONLJ",
        "outputId": "8f40ce38-b790-4dee-8526-704063173cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/4.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/4.5 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "VLF-hrWBKmod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22HAeuDqTolW",
        "outputId": "b7b1f618-92c1-4da5-f0a9-d140fe957759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function to transform the image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(image_path)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(input_tensor)# ebedding important line\n",
        "        return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "YtY6raX6Vrsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0AcRHbRVslq",
        "outputId": "4f243fd2-c507-44c7-8c67-cde1e11bed64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create python function where we provide image url and imag_name then it save in images folder\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download.\n",
        "    image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "dhtkU-0lV1-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4E03AQEEn9DuNlQwvw/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1664654245747?e=2147483647&v=beta&t=NGB0a9aqsgdyxpbuO3rqws95ogJnL_6aRtBDS7IWPfw\",\"s1.jpg\")\n",
        "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
        "\n",
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
        "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
        "save_image_from_url(\"https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\",'s2.jpg')\n",
        "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gSmY8gX8ep",
        "outputId": "e001bdf1-e5af-4a19-d871-884f6ba167c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/s1.jpg\n",
            "Image saved to: images/q1.jpg\n",
            "Image saved to: images/z1.jpg\n",
            "Image saved to: images/z2.jpg\n",
            "Image saved to: images/s2.jpg\n",
            "Image saved to: images/q2.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_image_from_url(\"data:image/jpeg;base64,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\",\"q2.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZJON-xwV-bl",
        "outputId": "45e5901e-9e00-4569-cd5c-50ced37e425c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading image: No connection adapters were found for 'data:image/jpeg;base64,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'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtpE6lWvW3gD",
        "outputId": "70c90a42-b13c-41a8-ed9d-de34d37786dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"./images/s2.jpg\"\n",
        "cat2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", cat2.shape)\n",
        "print(\"Image Embedding:\", cat2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmPsgV__Z5D-",
        "outputId": "e18d369b-65c8-4718-bda5-d42528588995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [-1.11871092e-02 -1.03831679e-01 -6.49788529e-02  6.26160726e-02\n",
            "  5.31825311e-02  2.93166805e-02  2.85817944e-02  1.07557606e-02\n",
            "  2.30576918e-02  2.11645626e-02  4.49966975e-02 -1.05079694e-03\n",
            "  5.12558147e-02 -1.57793239e-02  2.27004047e-02  4.33514714e-02\n",
            " -4.31503728e-02  3.46557088e-02  3.98752280e-02  4.01685536e-02\n",
            "  1.22629656e-02  3.47619690e-02  3.74376588e-02 -2.92636734e-02\n",
            " -1.95951890e-02  7.84217790e-02 -1.65973324e-02 -7.39309639e-02\n",
            "  1.87867340e-02 -3.93897295e-02 -3.14862356e-02  2.39189509e-02\n",
            " -2.03516819e-02 -3.26003097e-02  3.72588672e-02  1.85265020e-02\n",
            "  4.76108380e-02 -1.18853813e-02 -3.72915268e-02 -1.12608625e-02\n",
            " -1.34668415e-02  2.98970081e-02 -4.51772660e-02 -4.26033661e-02\n",
            " -5.81922904e-02 -1.54332519e-02  4.68713380e-02  8.94587934e-02\n",
            " -5.68718724e-02  1.97885297e-02 -1.02427714e-02  3.88370454e-02\n",
            "  1.36065371e-02  3.18910480e-02 -3.45597640e-02  1.28371874e-02\n",
            "  4.65074666e-02  5.49756736e-02 -4.13392968e-02 -1.22491121e-02\n",
            "  8.02586153e-02  3.81988622e-02 -5.95349297e-02 -4.23814692e-02\n",
            " -3.49300839e-02 -1.36340754e-02  1.65573079e-02 -9.17057693e-02\n",
            "  4.65478487e-02  4.74346522e-03 -7.06184953e-02  3.83565389e-02\n",
            " -2.63459440e-02 -2.60344408e-02  3.11261583e-02  1.57261752e-02\n",
            " -2.50283480e-02 -3.79884839e-02 -4.75553572e-02 -9.30941955e-04\n",
            "  2.56992294e-03 -1.16410665e-02 -2.28207912e-02 -1.37971453e-02\n",
            "  1.74771342e-03  3.25816385e-02  7.12756664e-02  8.06502923e-02\n",
            " -8.84141400e-02  3.10803317e-02  1.12167420e-02 -5.51299080e-02\n",
            "  2.68588867e-02  5.49648777e-02  5.49707972e-02  3.85880768e-02\n",
            "  6.21338785e-02 -4.84648123e-02 -8.64821225e-02  3.40486951e-02\n",
            " -1.84795298e-02 -1.02242075e-01  5.26406690e-02  1.47886546e-02\n",
            " -1.00119589e-02 -9.87762213e-02 -3.48315723e-02 -1.60418544e-02\n",
            "  5.70422830e-03  1.07697593e-02  4.71926183e-02  2.86004227e-02\n",
            " -7.81947225e-02 -1.11674763e-01 -2.46943682e-02 -6.18855916e-02\n",
            "  4.04402800e-02 -5.76940831e-03 -3.66969779e-02  8.73905346e-02\n",
            " -1.95407961e-03 -7.69524351e-02  2.24794121e-03  4.49692048e-02\n",
            " -3.32978033e-02 -2.64183376e-02 -7.62605900e-03 -4.31122668e-02\n",
            " -4.82989699e-02 -4.19171266e-02  6.26357496e-02 -1.28543442e-02\n",
            "  3.03642172e-02 -6.85790405e-02 -7.44268671e-02  4.44427580e-02\n",
            "  4.89318557e-02  7.48089999e-02  5.43042049e-02  6.00816235e-02\n",
            " -7.12566264e-03  8.05306341e-03  3.31095867e-02  7.52047971e-02\n",
            "  6.79623038e-02 -1.45985046e-02  1.66600458e-02  1.66200865e-02\n",
            " -1.90182421e-02 -2.40901653e-02  3.60215753e-02 -4.52494761e-03\n",
            " -2.01554149e-02 -3.92694548e-02 -6.22260990e-03 -6.53752685e-02\n",
            "  2.25214642e-02  1.63132250e-01  2.94811204e-02  1.35595500e-02\n",
            "  1.56537015e-02 -4.26869951e-02 -5.20180166e-02  2.30753869e-02\n",
            "  2.58502923e-02  4.04522233e-02 -7.47844577e-02 -9.00941938e-02\n",
            "  5.50987013e-02  1.23147229e-02  6.08907044e-02 -7.16004241e-03\n",
            "  5.38712330e-02 -8.02025273e-02  5.18828854e-02 -4.00018580e-02\n",
            " -5.88896498e-02 -1.56445596e-02 -6.38517365e-02  7.16072917e-02\n",
            " -9.03155804e-02  2.27934793e-02 -6.62763342e-02  6.39582053e-04\n",
            "  2.69628260e-02  5.58275171e-02  7.03577921e-02 -6.42892485e-03\n",
            " -7.07693622e-02 -5.25698066e-02 -2.28427649e-02 -1.37585355e-02\n",
            "  5.22842593e-02 -3.93862315e-02 -1.84570011e-02 -1.30426968e-02\n",
            " -1.33173876e-02  1.35453995e-02 -2.80390326e-02  5.79056144e-02\n",
            "  7.42083117e-02  4.26574275e-02 -7.73473307e-02 -7.72884861e-02\n",
            " -6.86476380e-02  4.26337533e-02 -3.17118168e-02 -3.85838673e-02\n",
            " -3.27074490e-02  2.25020368e-02 -5.35984933e-02 -8.51002261e-02\n",
            " -2.57829379e-04 -5.79836592e-02 -4.83230464e-02  6.95719942e-02\n",
            " -5.70446579e-03  3.79940495e-02  3.91066223e-02  8.65514018e-03\n",
            " -1.94135103e-02 -8.58654976e-02 -2.17920132e-02 -3.61560769e-02\n",
            "  1.96798276e-02  7.68107409e-03 -4.60527949e-02 -6.16294369e-02\n",
            "  1.40599320e-02 -1.96032431e-02  3.69630717e-02  3.76747772e-02\n",
            " -3.93913011e-04 -5.43305613e-02 -4.82097920e-03  7.32045919e-02\n",
            "  2.96099130e-02 -1.40450243e-02 -7.42208771e-03 -1.03640500e-02\n",
            " -3.25925536e-02 -3.01711783e-02 -1.41784605e-02  1.91026032e-02\n",
            "  1.19687105e-02  5.49073629e-02 -1.27675049e-02  1.89592652e-02\n",
            " -3.60129704e-03  4.07527685e-02  1.58893522e-02 -3.44600640e-02\n",
            "  1.06150880e-02  3.84745449e-02  6.57472461e-02  3.69573571e-02\n",
            " -7.59413615e-02  7.12694554e-03  1.02292381e-01  3.07430904e-02\n",
            " -1.42631624e-02 -3.66568081e-02  4.19115573e-02  2.91144066e-02\n",
            " -2.39088945e-02 -1.75305735e-02  2.30969545e-02  1.10883974e-02\n",
            " -2.20475420e-02  9.80181340e-03  5.87587245e-03  3.13788243e-02\n",
            " -6.55176118e-02  2.09741853e-03  5.72765693e-02 -1.58681860e-03\n",
            " -4.68703508e-02 -1.52097307e-02 -7.16491938e-02  2.99625471e-02\n",
            " -6.92216959e-03 -3.35283726e-02 -2.81945970e-02 -3.25089544e-02\n",
            " -6.62789941e-02 -4.97282185e-02 -3.42484340e-02 -2.92028184e-03\n",
            " -3.12268082e-02 -2.36473512e-03  6.91680908e-02 -5.72880507e-02\n",
            "  2.19719894e-02  7.09659457e-02 -9.11697820e-02  8.05146247e-03\n",
            " -3.67003754e-02 -3.51633504e-02 -3.51897813e-02 -4.24067210e-03\n",
            "  7.31516723e-03  3.96723077e-02  1.22136600e-01  9.59074348e-02\n",
            "  3.37592028e-02 -8.30706581e-02 -4.62482125e-02  5.29494435e-02\n",
            " -6.37108311e-02 -7.88331628e-02  2.41478123e-02  3.51880379e-02\n",
            "  3.10061988e-03 -8.55734048e-04  9.33466479e-03  9.05917734e-02\n",
            " -5.29304240e-03 -5.91451349e-03 -3.49753648e-02 -3.79948057e-02\n",
            " -1.01735713e-02  1.44569213e-02 -3.40275578e-02  5.79419993e-02\n",
            " -6.94063231e-02  5.42249419e-02  4.10679402e-03 -2.00269953e-03\n",
            " -3.38053657e-03  5.25264814e-02  8.21771193e-03 -1.42585263e-02\n",
            "  3.32685071e-03  4.92198113e-03 -6.54617976e-03  1.02857854e-02\n",
            "  8.78617838e-02 -5.40974829e-03 -4.90192790e-03 -2.69505940e-02\n",
            "  1.16487309e-01 -1.11756781e-02 -5.35591925e-03  1.03215575e-02\n",
            "  9.29426774e-03 -6.83753490e-02 -5.87190082e-03  5.61574586e-02\n",
            " -2.96462979e-02 -1.24421641e-02 -2.96109170e-02  3.14039290e-02\n",
            "  1.07058501e-02  1.78728383e-02  1.22983707e-02  3.82478572e-02\n",
            "  8.27867389e-02 -2.93790568e-02  8.19675811e-03  3.53541337e-02\n",
            "  1.54894055e-03  6.46627173e-02  1.66487310e-03 -4.24213782e-02\n",
            " -7.26400912e-02  6.79494515e-02  8.68740026e-03 -8.92815646e-03\n",
            "  2.97773303e-03 -3.14534493e-02 -2.34413091e-02  2.59234216e-02\n",
            " -3.53894010e-02  1.58237852e-02 -9.52033792e-03 -1.04601365e-02\n",
            " -3.72940972e-02  9.96353384e-03  3.83030740e-03  1.09600406e-02\n",
            " -2.67700199e-03  3.83338295e-02  6.69002682e-02  5.93743697e-02\n",
            "  1.16633736e-01 -6.55779615e-02 -1.49554471e-02 -3.90407965e-02\n",
            " -3.73179391e-02  3.14061157e-02  5.28097264e-02 -3.25627774e-02\n",
            " -3.03207189e-02 -4.85909283e-02 -3.29659134e-02 -2.05135643e-02\n",
            "  2.61528362e-02  3.25204283e-02  3.23005988e-05 -2.75909379e-02\n",
            " -6.97963536e-02 -3.12910601e-03 -1.11005129e-02  1.16420761e-02\n",
            " -8.27886760e-02  5.85027412e-02 -1.77270323e-02 -2.46270373e-02\n",
            " -1.12117054e-02 -4.60258499e-02  5.06376028e-02 -3.59613001e-02\n",
            "  9.49118193e-03 -3.65367532e-02 -6.32456467e-02 -7.98258279e-03\n",
            "  1.70360636e-02  1.34473937e-02  9.58526693e-03 -5.80657721e-02\n",
            "  4.14541624e-02 -3.09430752e-02 -1.94751471e-02  4.93912958e-02\n",
            "  6.71683857e-03  5.04589938e-02  4.60711122e-02  8.14810675e-03\n",
            "  4.14786424e-04 -5.30870110e-02  4.03976515e-02  3.44096720e-02\n",
            "  2.18358040e-02  8.94732028e-03 -8.08790401e-02  1.38119273e-02\n",
            "  4.42448147e-02  2.45676450e-02 -8.20356831e-02 -2.84231603e-02\n",
            " -2.38482263e-02  4.76225354e-02 -6.49007410e-02  4.62613478e-02\n",
            "  1.12036755e-02 -6.22173846e-02 -2.37915777e-02  1.36410967e-02\n",
            " -5.50070927e-02 -4.87210602e-03  4.57302146e-02  3.77252176e-02\n",
            "  4.11336459e-02 -6.46088272e-03  7.15470240e-02 -1.30598292e-01\n",
            "  5.94469868e-02  5.49982078e-02  6.16098642e-02  4.15492579e-02\n",
            " -1.65865161e-02  9.11596268e-02  1.50168948e-02  5.86488023e-02\n",
            "  3.52287665e-02  5.36219515e-02 -2.27170866e-02  2.38616634e-02\n",
            "  5.69305196e-02 -5.61067089e-02 -1.63862202e-02 -7.68495025e-03\n",
            " -7.35249231e-03 -2.82694027e-02 -2.63305176e-02 -1.63035244e-02\n",
            " -2.63792966e-02 -2.06475402e-03 -3.17978999e-03 -1.68414932e-04\n",
            " -3.67765166e-02  8.34158901e-03  9.04802233e-02 -5.55233611e-03\n",
            "  5.70693016e-02  4.57675941e-02  6.21742709e-03  8.65672948e-04\n",
            " -4.08265274e-03 -8.40259567e-02  1.97605304e-02 -2.01635025e-02\n",
            "  5.56236785e-03  6.52863011e-02  1.03389621e-01  2.02528182e-02\n",
            "  1.90992840e-02 -2.93199196e-02 -1.71488412e-02 -4.66644801e-02\n",
            " -6.03761850e-03 -1.08810216e-02 -1.04834288e-02 -1.31510189e-02\n",
            " -3.51735875e-02 -1.67632438e-02  4.90136743e-02 -1.90571100e-02\n",
            "  2.45440360e-02  1.26176523e-02 -3.38700116e-02 -2.57172789e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
        "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
        "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
        "s2 = create_image_embedding(\"./images/s2.jpg\")\n",
        "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
        "z2 = create_image_embedding(\"./images/z2.jpg\")"
      ],
      "metadata": {
        "id": "qGsGyHm7Z7GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U milvus-lite\n",
        "\n",
        "!pip install -U pymilvus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaGMoOeMatEn",
        "outputId": "1f826ba3-19a3-4d7b-e8c8-c1b96e777e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: milvus-lite in /usr/local/lib/python3.10/dist-packages (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite) (4.67.1)\n",
            "Requirement already satisfied: pymilvus in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (75.1.0)\n",
            "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.67.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (4.25.5)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.0.1)\n",
            "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.10.0)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n"
      ],
      "metadata": {
        "id": "8VCan5cjbCBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
        ")"
      ],
      "metadata": {
        "id": "lhSATnNMaZmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
        "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
        "    {\"id\": 3, \"person_name\": \"Shahzad\", \"vector\": s1},\n",
        "    {\"id\": 4, \"person_name\": \"Shahzad\", \"vector\": s2},\n",
        "    {\"id\": 5, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
        "    {\"id\": 6, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "bB-wjZmIarV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ],
      "metadata": {
        "id": "pPFMGNspcEnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[s1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E3TbHNIaZsF",
        "outputId": "8b9a3cc2-636a-4fc3-e437-de805ecef25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 3, 'distance': 1.0, 'entity': {'person_name': 'Shahzad', 'id': 3}}]\"] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q3 = create_image_embedding('./images/q3.jpg')\n",
        "q3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWjC3uQyaZ0h",
        "outputId": "316cf3e9-db97-4414-eb9d-b67ea9664c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.49765784e-02, -3.95101458e-02, -3.39875631e-02,  3.52344252e-02,\n",
              "        8.82505812e-03, -9.46294330e-03, -2.02523619e-02,  3.26745561e-04,\n",
              "       -1.25470031e-02, -1.70428045e-02,  1.14811892e-02, -4.24311645e-02,\n",
              "       -5.85023779e-03,  1.51661877e-02,  6.88413382e-02,  2.30133291e-02,\n",
              "       -7.88090006e-03,  5.66428602e-02, -7.11421948e-03,  2.42894143e-03,\n",
              "        1.88995767e-02,  4.74441871e-02,  5.68169169e-02,  1.30824992e-05,\n",
              "       -2.91658957e-02,  5.05764037e-02,  8.83970316e-03, -5.82928099e-02,\n",
              "       -1.60568617e-02, -7.94354975e-02,  2.07029209e-02,  9.93780717e-02,\n",
              "        1.28378011e-02,  5.21188825e-02,  4.21005161e-03, -1.89065561e-02,\n",
              "        3.68318595e-02,  3.10832984e-03, -4.76457998e-02, -5.60111664e-02,\n",
              "       -1.16198752e-02, -5.90130202e-02,  1.02151297e-02, -1.85261946e-03,\n",
              "        1.15303956e-02, -2.90563554e-02, -9.58734378e-03, -1.97601859e-02,\n",
              "       -9.42032412e-02,  1.53519837e-02,  2.53812093e-02,  2.14174315e-02,\n",
              "        2.21368554e-03,  1.46285398e-02, -4.69658971e-02, -2.02091355e-02,\n",
              "        4.22882941e-03, -3.25385015e-03,  7.23441988e-02,  2.23042276e-02,\n",
              "        7.19925901e-03,  1.65719166e-02, -3.79756764e-02, -1.16910478e-02,\n",
              "       -1.67125147e-02,  3.46974134e-02, -5.93688758e-03, -5.00005186e-02,\n",
              "        5.81429452e-02,  2.45740842e-02, -5.24211712e-02, -6.71044737e-02,\n",
              "        6.30113930e-02,  4.78395522e-02,  3.35798301e-02,  1.48839457e-02,\n",
              "       -1.88941583e-02, -4.63252664e-02, -4.83563058e-02,  1.32286269e-02,\n",
              "        8.54715779e-02,  5.85637651e-02, -4.73560058e-02, -5.20822499e-03,\n",
              "       -9.27715842e-03,  4.12191451e-02,  2.21475679e-02,  8.02465230e-02,\n",
              "       -7.95414820e-02, -1.41363805e-02, -7.50593990e-02,  1.46668861e-02,\n",
              "        7.97520503e-02,  4.23329771e-02, -1.01549374e-02,  9.68345255e-03,\n",
              "       -5.62676899e-02, -2.76991515e-03, -4.50135395e-02, -3.63397114e-02,\n",
              "       -2.88632512e-03,  3.14908624e-02,  6.61040144e-03, -1.19037023e-02,\n",
              "        1.83691792e-02, -5.10664135e-02,  1.97625272e-02, -1.35700315e-01,\n",
              "       -8.25428739e-02, -5.24217859e-02, -3.59555557e-02, -3.13281529e-02,\n",
              "       -8.72447118e-02, -7.45845884e-02, -5.31625876e-04, -3.61732766e-02,\n",
              "        2.95988601e-02, -4.87455539e-02, -8.31213221e-02,  5.93954772e-02,\n",
              "       -3.35073769e-02,  2.81962380e-02, -5.13702855e-02,  6.04946390e-02,\n",
              "       -8.24005380e-02, -6.62563965e-02,  3.00803427e-02, -4.77372520e-02,\n",
              "        8.86089876e-02, -1.14682876e-02,  2.85840165e-02, -1.79408733e-02,\n",
              "        2.91705839e-02, -2.59475838e-02, -3.44714262e-02,  1.72092523e-02,\n",
              "        2.10048668e-02, -8.81040171e-02,  4.90192929e-03,  3.91785009e-03,\n",
              "        5.66373318e-02,  4.85491864e-02, -7.00368453e-03,  2.91876998e-02,\n",
              "        4.37514260e-02, -4.69061136e-02, -3.28719020e-02, -2.56725010e-02,\n",
              "        5.08666523e-02,  2.94409208e-02, -9.50891804e-03,  3.70850414e-03,\n",
              "       -2.54460014e-02,  6.14704564e-04,  9.70900897e-03, -8.83906707e-02,\n",
              "       -8.99428055e-02,  2.05951277e-02,  8.50876514e-03, -9.66524035e-02,\n",
              "        1.48862572e-02,  1.45156048e-02,  3.08693983e-02,  5.59280477e-02,\n",
              "        4.22499105e-02, -2.95278840e-02, -1.42858341e-01,  2.16566380e-02,\n",
              "        4.70048003e-02, -3.33615555e-03,  1.26746586e-02,  1.58542916e-02,\n",
              "       -6.06146306e-02,  5.68511104e-03, -3.41108106e-02, -2.23597344e-02,\n",
              "       -5.75657263e-02,  6.71762303e-02, -2.92481836e-02,  8.91443044e-02,\n",
              "       -1.72110293e-02,  2.31837146e-02, -9.36505198e-03, -3.47036049e-02,\n",
              "        5.11917286e-02, -2.45199818e-02,  3.19132581e-02,  1.30963679e-02,\n",
              "        3.70483659e-02,  4.93873097e-02,  4.58216593e-02,  3.11194919e-02,\n",
              "        5.87021038e-02,  2.86020339e-02,  6.03839429e-03,  3.68666798e-02,\n",
              "       -1.03881704e-02,  1.70054531e-03,  1.17167337e-02,  1.98467784e-02,\n",
              "        1.48200378e-01,  3.59525084e-02,  4.23457846e-02,  3.62095647e-02,\n",
              "       -7.11338688e-03,  3.17213312e-02,  3.22097614e-02,  2.77051255e-02,\n",
              "       -3.17094289e-02,  9.15603265e-02,  3.56624648e-02,  7.60837877e-03,\n",
              "       -3.69629189e-02,  9.58454162e-02, -5.32883592e-02,  4.34087701e-02,\n",
              "        4.29520831e-02, -5.41078933e-02, -5.00095561e-02,  3.44248079e-02,\n",
              "       -1.36768157e-02, -1.14533224e-03,  1.69692039e-02,  5.39893582e-02,\n",
              "        2.69198399e-02, -1.93695035e-02, -2.71186908e-03,  1.06195994e-02,\n",
              "       -1.95283275e-02,  1.61357839e-02,  2.42574606e-02, -3.78023610e-02,\n",
              "        1.51027804e-02, -4.71470058e-02, -5.00968285e-02,  6.34373259e-03,\n",
              "       -2.04296447e-02,  3.89486477e-02,  7.17150047e-02, -6.10053428e-02,\n",
              "        2.65750512e-02, -7.69235846e-03,  2.91217715e-02,  2.20773648e-02,\n",
              "       -3.05016451e-02,  9.57315862e-02,  1.06307575e-02,  3.82872336e-02,\n",
              "        1.21221440e-02,  8.73533785e-02, -5.14507368e-02, -5.76517079e-03,\n",
              "        1.51621243e-02, -4.92335930e-02, -2.24688556e-03, -4.28351387e-02,\n",
              "       -3.75622995e-02,  2.14859080e-02,  1.79149862e-02, -3.97252329e-02,\n",
              "        8.63847602e-03, -3.61412764e-02,  2.14099907e-03, -1.65015366e-02,\n",
              "       -7.00033084e-03, -3.65552567e-02,  1.67008638e-02, -1.40723968e-02,\n",
              "        6.63336192e-04, -3.67025658e-02,  3.77225168e-02, -1.21849934e-02,\n",
              "        2.83187851e-02,  8.35291576e-03,  6.13777153e-02,  4.03296836e-02,\n",
              "       -4.52169925e-02, -9.03317705e-03,  3.94935347e-03,  1.14877924e-01,\n",
              "       -2.87455842e-02, -2.69201603e-02, -8.28011706e-02, -1.00298077e-01,\n",
              "        1.41426222e-02, -3.26199853e-03, -3.35870720e-02, -2.41020340e-02,\n",
              "        1.65404137e-02,  5.28325513e-02,  2.12855563e-02,  3.72219346e-02,\n",
              "        6.70698732e-02,  4.13109921e-03, -1.05351647e-02, -1.42203895e-02,\n",
              "       -4.33747955e-02, -3.88956890e-02,  3.01676467e-02, -1.24645419e-02,\n",
              "        2.78728898e-03, -6.93244208e-03,  3.77367474e-02,  2.24253759e-02,\n",
              "        2.42200438e-02, -2.13177819e-02, -1.45046674e-02, -5.14064822e-03,\n",
              "        2.55382899e-03, -4.37453426e-02, -4.83091213e-02,  8.98236111e-02,\n",
              "        3.99637595e-02, -2.16076430e-02, -2.78507266e-03,  7.66610056e-02,\n",
              "        9.76247620e-03,  2.37820428e-02,  1.03054449e-01, -2.85051279e-02,\n",
              "        4.57690004e-03, -1.06987581e-01,  1.65460887e-03,  1.08399307e-02,\n",
              "       -3.31568271e-02,  1.15578780e-02, -4.62076738e-02,  3.42738554e-02,\n",
              "       -3.09151318e-02,  2.69689914e-02,  5.60879800e-03,  2.15870291e-02,\n",
              "       -5.13517968e-02,  3.65614099e-03, -1.85999516e-02,  5.32488339e-02,\n",
              "        1.00007923e-02, -9.26879421e-02,  1.24752680e-02, -9.89166796e-02,\n",
              "        1.49804279e-02, -3.67246894e-03, -2.68669352e-02, -4.34258021e-02,\n",
              "        9.21010133e-03, -2.08337456e-02, -3.76179232e-03,  7.74091333e-02,\n",
              "       -3.93624529e-02,  7.34356716e-02, -2.57823570e-03, -2.88213454e-02,\n",
              "        6.49443921e-03,  2.83528194e-02,  3.98588032e-02,  8.81356895e-02,\n",
              "       -2.97437273e-02, -2.48173177e-02, -3.52805108e-02,  4.81878743e-02,\n",
              "       -2.10914239e-02, -2.45536765e-04,  3.96146402e-02, -4.09000441e-02,\n",
              "       -3.00859325e-02,  1.26508474e-02, -2.39239330e-03,  2.71387380e-02,\n",
              "        2.14878172e-02, -7.97066689e-02,  4.82078362e-03,  2.72272062e-02,\n",
              "       -4.27303687e-02,  1.63216852e-02, -2.89588850e-02,  9.07153562e-02,\n",
              "       -3.92286181e-02,  6.28829598e-02, -1.63904354e-02,  1.74034052e-02,\n",
              "       -5.24871461e-02,  2.79299989e-02,  4.41449471e-02,  3.81703302e-02,\n",
              "        6.02327138e-02, -6.01882450e-02, -2.07202160e-03, -2.38520978e-03,\n",
              "       -9.22099396e-04, -3.50860320e-02, -1.79485567e-02, -3.99851501e-02,\n",
              "        3.80258188e-02,  5.81928436e-03, -1.75062940e-02, -1.43912220e-02,\n",
              "       -1.88390054e-02,  1.13170154e-01, -6.40609637e-02, -7.23131821e-02,\n",
              "       -2.05054078e-02, -6.02426752e-02,  1.20316660e-02, -7.48610031e-03,\n",
              "       -1.72596369e-02, -2.73319776e-03, -9.65450704e-03, -7.41420239e-02,\n",
              "       -1.68084763e-02,  2.74238866e-02,  7.50973970e-02, -3.15075815e-02,\n",
              "        6.06773570e-02, -1.77636102e-03, -2.06731055e-02,  5.71253486e-02,\n",
              "        2.01734789e-02, -4.96521592e-02, -4.13238257e-02, -1.98553074e-02,\n",
              "        7.33709801e-03, -3.04019824e-02, -1.86798777e-02,  2.37525664e-02,\n",
              "       -6.32604286e-02,  2.93251649e-02, -1.79723219e-03,  3.39430980e-02,\n",
              "        5.32454103e-02, -7.52142817e-02, -6.06065691e-02, -2.46305298e-02,\n",
              "       -5.46315275e-02, -1.14637792e-01,  2.92891301e-02,  6.10700585e-02,\n",
              "        1.22949118e-02, -3.20320129e-02,  1.44228889e-02, -9.99345444e-03,\n",
              "       -5.09206802e-02,  4.04192619e-02, -4.40445244e-02,  6.55966103e-02,\n",
              "        3.19262929e-02, -3.24597582e-02, -1.71565190e-02,  2.46003158e-02,\n",
              "       -1.54929206e-04,  2.33350229e-02, -1.62446091e-03,  6.09595440e-02,\n",
              "       -2.68336702e-02, -1.93970222e-02, -3.52038518e-02, -2.32867710e-02,\n",
              "       -5.97450323e-02,  7.15385079e-02,  8.50118101e-02,  1.17288440e-01,\n",
              "       -1.72792338e-02,  5.80070727e-02,  6.03232868e-02,  3.53287980e-02,\n",
              "       -3.21235247e-02, -2.19052732e-02, -6.67875931e-02, -2.42928434e-02,\n",
              "        8.29760879e-02,  6.00026697e-02,  3.45895737e-02,  4.89646792e-02,\n",
              "       -2.53018923e-02, -4.90279421e-02, -4.04543690e-02, -3.82700823e-02,\n",
              "       -2.68285517e-02,  3.49381659e-03,  3.01038437e-02, -1.46813039e-03,\n",
              "       -6.02994114e-02, -5.70144691e-02,  2.13950817e-02,  2.92146280e-02,\n",
              "        1.90934688e-02, -7.78953508e-02, -2.21378524e-02,  5.67838699e-02,\n",
              "        2.35221852e-02, -1.11557662e-01,  1.21968761e-02, -1.14665940e-01,\n",
              "        5.06443419e-02,  2.89933756e-03,  2.38087531e-02, -5.64510599e-02,\n",
              "        8.37108865e-02,  1.07489107e-02,  5.00915237e-02, -4.55174930e-02,\n",
              "        2.31523290e-02,  1.59411263e-02, -1.00823574e-01,  4.34959419e-02,\n",
              "       -7.62930736e-02,  1.27093736e-02,  3.87201384e-02, -4.75631282e-02,\n",
              "       -4.31633145e-02,  3.62972580e-02,  7.42781535e-03, -4.45608199e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[q3],\n",
        "    limit=2,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr7oM5Otf2My",
        "outputId": "e9c30450-f816-4741-ad6c-0199b8672637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 0.525050163269043, 'entity': {'person_name': 'Qasim', 'id': 1}}]\"] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kaxs40aDamtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}